# Memo√Øsation
L√©o Filoche - ESIR3 SI - Cours de HPC
## Installation
```bash
# Clone this repo
git clone https://gitlab.istic.univ-rennes1.fr/lfiloche/hpc4subsetsum.git
# Create the build folder for execution
mkdir build
```
## Ex√©cution
```bash
gcc -o build/ssp ssp.c -fopenmp -lm && ./build/ssp
```
## Introduction
>**memo√Øsation** : Technique d'optimisation de code consistant √† r√©duire le temps d'ex√©cution d'une fonction en m√©morisant ses r√©sultats d'une fois √† l'autre
> <cite>Wiktionnaire</cite>

Dans le cadre du *Subset Sum Problem*, la technique de memo√Øsation se traduit par l'utilisation d'un tableau, dans lequel sont stock√©s tous les r√©sultats de calculs pr√©c√©dents.  Ce tableau est nomm√© ```sumMemory``` dans l'impl√©mentation de cette technique (fichier ```filoche.c```).

## Source
Plusieurs sites √©voquent l'utilisation de la m√©thode de m√©moisation dans le cadre du Subset Sum Problem. Le site [favtutor](https://favtutor.com/blogs/subset-sum-problem) fut ma r√©f√©rence dans la compr√©hension et dans l'impl√©mentation de l'approche r√©cursive de la m√©moisation. Les deux autres approches (it√©rative et parall√©lis√©e) ont √©t√© r√©fl√©chies et impl√©ment√©es par moi-m√™me.

## Approches
Il existe plusieurs approches pour impl√©menter utiliser de la m√©moisation dans la r√©solution du *Subset Sum Problem*. 

### Approche r√©cursive (```memoization_sequential_recursive```)
L'approche qui est habituellement utilis√©e est l'approche **r√©cursive**, car elle est intuitive et garde la m√™me logique que l'approche na√Øve de r√©solution du *SSP*. La seule diff√©rence est que l'on utilise un tableau (*sumMemory*) pour ne pas avoir √† effectuer plusieurs fois le m√™me calcul. Dans cette approche r√©cursive, on part de la "fin" (derni√®re ligne, derni√®re colonne). Celle ci vaut ```true``` si :
- Consid√©rer la valeur courante (la derni√®re valeur du tableau) permet d'obtenir la valeur ```target```.
- Consid√©rer les valeurs pr√©c√©dentes (ignorer la valeur courante en r√©duisant la taille du tableau de ```1```) permet d'obtenir la valeur ```target``` 


#### Exemple

```
a={5, 3, 2, 3} // set of reference
n = 4 // a.length
target = 11 // sum to find in a

sumMemory =
   0Ô∏è‚É£1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£8Ô∏è‚É£9Ô∏è‚É£üîü11
0:5üÜïüÜïüÜïüÜïüÜï‚úÖ‚ùåüÜï‚ùå‚ùåüÜï‚ùå
1:3üÜïüÜïüÜïüÜïüÜïüÜïüÜïüÜï‚úÖ‚ùåüÜï‚ùå
2:2üÜïüÜïüÜïüÜïüÜïüÜïüÜïüÜï‚úÖüÜïüÜï‚ùå
3:3üÜïüÜïüÜïüÜïüÜïüÜïüÜïüÜïüÜïüÜïüÜï‚úÖ

sumMemory[3][11]=‚úÖ => subset sum exists !
```

Les cellules üÜï sont celles dont la valeur n'a jamais √©t√© modifi√©e. <br>
Les cellules ‚úÖ sont celles dont la valeur est ```true```. <br>
Les cellules ‚ùå sont celles dont la valeur est ```false```. 

La lecture du tableau est la suivante :
- la cellule ```sumMemory[3][11]``` indique qu'il est possible d'obtenir la valeur cible ```11``` en prenant en compte l'ensemble de ```a```. 
- la cellule ```sumMemory[2][8]``` indique qu'il est possible d'obtenir la valeur cible ```8``` en prenant en compte un sous-ensemble comprenant les 3 premi√®res valeurs de ```a```, √† savoir ```{5, 3, 2}```
- la cellule ```sumMemory[1][8]``` indique qu'il existe un sous-ensemble comprenant les 2 premi√®res valeurs de ```a```, √† savoir ```{5, 3}``` permettant d'atteindre la valeur cible ```8```
- la cellule ```sumMemory[0][5]``` indique qu'il existe un sous-ensemble comprenant la premi√®re valeur de ```a```, √† savoir ```{5}```

On en d√©duit donc qu'on obtient ```11``` avec ```3``` (valeur de ```a[3]```), ```3``` (valeur de ```a[1]```), et ```5``` (valeur de ```a[0]```), autrement dit avec le sous-ensemble ```{3, 3, 5}``` 

### Approche it√©rative (```memoization_sequential_iterative```)
Bien qu'inhabituelle, il a √©t√© n√©cessaire d'impl√©menter l'**approche it√©rative** pour parall√©liser le programme avec *OpenMP*. Cette approche passe en revue chaque case du tableau ```a``` et en d√©duit toutes les valeurs de sommes possibles. 

La construction du tableau est diff√©rente, au lieu d'√™tre *s√©lective*, elle est *cumulative* : chaque ligne d√©pend de la pr√©c√©dente, √† laquelle on a ajout√© la valeur de la case courante de ```a``` dans l'√©quation. 

#### Exemple

En reprennant l'exemple ci-dessus, voici le tableau *sumMemory* qui en d√©coule.
```
sumMemory =
   0Ô∏è‚É£1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£8Ô∏è‚É£9Ô∏è‚É£üîü11
0:5‚ùå‚ùå‚ùå‚ùå‚ùå‚úÖ‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå
1:3‚ùå‚ùå‚ùå‚úÖ‚ùå‚úÖ‚ùå‚ùå‚úÖ‚ùå‚ùå‚ùå
2:2‚ùå‚ùå‚úÖ‚úÖ‚ùå‚úÖ‚ùå‚úÖ‚úÖ‚ùå‚úÖ‚ùå
3:3‚ùå‚ùå‚úÖ‚úÖ‚ùå‚úÖ‚úÖ‚úÖ‚úÖ‚ùå‚úÖ‚úÖ

sumMemory[3][11]=‚úÖ => subset sum exists !
```
Bien que le tableau final soit diff√©rent, la lecture est toujours la m√™me : on part de la derni√®re cellule, on se d√©calle horizontalement de la valeur de a[i], et verticalement tant que la valeur de v√©rit√© est √† ```true```. 

Ici, ```sumMemory[3][11]```, ```sumMemory[1][8]```, ```sumMemory[0][5]``` sont donc √† prendre en compte, et renseignent que le sous-ensemble ```{3, 3, 5}``` forme la solution esp√©r√©e.

### Approche it√©rative parall√©lis√©e (```memoization_parallel_iterative```)
Cette approche est fonci√®rement la m√™me que l'approche it√©rative d√©crite pr√©c√©demment (*s√©quentielle*). La seule diff√©rence est que la construction de *sumMemory* est multithread√©e. Le *multithreading* a lieu au niveau de la construction des cellules d'une m√™me ligne. Dans l'exemple, si 2 threads √©taient allou√©s, lors du traitement d'une ligne fix√©e, les cellules allant de l'indice ```0``` √† l'indice ```5``` compris seraient trait√©es par un thread, et les cellules allant de l'indice ```6``` √† l'indice ```11``` compris seraient trait√©es par un autre thread.

On pourrait vouloir parall√©liser plus, c'est-√†-dire parall√©liser au niveau des lignes (avec 2 threads, la ligne ```0``` et ```1``` pour un thread, et ```2``` et ```3``` l'autre thread). Cependant, chaque ligne d√©pendant de la pr√©c√©dente, on ne peut pas agir √† ce niveau concernant la parall√©lisation.

## Performances
Afin de pouvoir comparer les 3 approches, leurs performances ont √©t√© enregistr√©es selon diff√©rents param√®tres. Voici les r√©sultats.

### 1. La valeur de la cible
<img src="assets/valeur_cible.png" width=400>

|param√®tre | valeur|
|----------| -----|
|n | 1000| 
|maximum element value | 10000|
|NUM_THREADS | 5 |

### 2. La taille de l'ensemble
<img src="assets/cardinalite.png" width=400>

|param√®tre | valeur|
|----------| -----|
|target | 1000| 
|maximum element value | 10000|
|NUM_THREADS | 5 |

### 3. Le nombre de threads utilis√©s
<img src="assets/parallelisation.png" width=400>

|param√®tre | valeur|
|----------| -----|
|n | 100000 |
|target | 1234| 
|maximum element value | 10000|


## Observations

<p align="justify">
A la vue de ces r√©sultats, on fait le constat que l'utilisation de la m√©thode it√©rative actuelle n'est pas optimale et ne permet pas de remplacer la m√©thode r√©cursive.
Cela s'explique sans doute par le fait que la m√©thode r√©cursive se concentre sur le probl√®me √† r√©soudre (la somme √† trouver), tandis que la m√©thode it√©rative calcule toutes les sommes possibles entre les √©l√©ments de l'ensemble.

On observe que la parall√©lisation des calculs relatifs √† chaque √©l√©ment de l'ensemble permet d'am√©liorer l√©g√®rement les performances lorsque la valeur cible est √©lev√©e. Cela correspond √† notre intuition : la parall√©lisation consiste √† d√©l√©guer les calculs √† plusieurs fils d'ex√©cution distincts, de sorte √† faire plus de traitement pendant une m√™me p√©riode donn√©e.
Cependant cette am√©lioration est √† nuancer : la cr√©ation de nouveaux threads a un co√ªt significatif. De plus, la dur√©e de traitement de chaque ligne de *sumMemory* d√©pend de celle du thread le plus long (il faut attendre que tous les threads aient termin√© pour pouvoir traiter la ligne suivante).
Si, au d√©part, la multiplication du nombre de threads s'av√®re int√©ressante, √† partir d'un certain seuil cela n'est plus si √©vident. Dans les cas √©tudi√©s, l'utilisation de 5 threads (sur 8 possibles) peut donc √™tre qualifi√©e de raisonnable. 
<p>

## Conclusion
<p align="justify">
Pour conclure, on note que la technique de m√©moisation initiale, √† savoir r√©cursive est une bonne m√©thode. Stocker les valeurs des calculs effectu√©s pr√©c√©demment pour √©viter d'avoir √† les refaire est une bonne id√©e et se ressent au niveau des performances. Cependant, une approche na√Øve de sa version it√©rative rend les performances moins bonnes car elle consiste √† effectuer <b>tous</b> les calculs possibles, et donc plus de calculs !
Une parall√©lisation de cette m√©thode na√Øve en am√©liore les performances, mais pas au point de d√©passer la m√©thode initiale (r√©cursive). Si l'on souhaite optimiser cette approche, il faudrait faire en sorte de faire seulement les calculs n√©cessaires √† la recherche d'un sous ensemble.

Enfin, (et ce n'est pas √† n√©gliger), quelle que soit la m√©thode utilis√©e, l'utilisation de la m√©moisation est contrainte par l'espace m√©moire. Ce qui fait sa force, est aussi sa faiblesse : pour des valeurs cibles tr√®s grandes ou des ensembles tr√®s grands, cette m√©thode n'est pas applicable.
</p>